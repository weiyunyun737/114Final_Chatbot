import os
os.environ["STREAMLIT_WATCHER_TYPE"] = "none"

import streamlit as st
import requests
from langchain_community.vectorstores import FAISS
from langchain_community.embeddings import HuggingFaceEmbeddings

st.set_page_config(page_title="å®¢æœtest", page_icon="ğŸ’¬")
st.markdown("<h1 style='font-size:30px; color:#F63366;'>å®¢æœæ©Ÿå™¨äººå°å¹«æ‰‹ ğŸ’¬</h1>", unsafe_allow_html=True)
st.markdown("æ‚¨å¥½ï¼Œæœ‰ä»»ä½•å•é¡Œéƒ½å¯ä»¥å•æˆ‘å–”ï¼")

OPENROUTER_API_KEY = st.secrets.get("OPENROUTER_API_KEY") or os.getenv("OPENROUTER_API_KEY")
if not OPENROUTER_API_KEY:
    st.error("âŒ è«‹å…ˆè¨­å®šä½ çš„ OpenRouter API Keyï¼ˆç’°å¢ƒè®Šæ•¸æˆ– secretsï¼‰")
    st.stop()

faq_responses = {
    "å¦‚ä½•è¯çµ¡å®¢æœ": "æ‚¨å¯ä»¥é€é support@example.com è¯çµ¡æˆ‘å€‘çš„å®¢æœåœ˜éšŠã€‚",
    "ç‡Ÿæ¥­æ™‚é–“": "æˆ‘å€‘çš„å®¢æœç‡Ÿæ¥­æ™‚é–“ç‚ºé€±ä¸€è‡³é€±äº” 09:00 è‡³ 18:00ã€‚",
    "ä½ æ˜¯èª°": "æˆ‘æ˜¯ OpenRouter èŠå¤©å®¢æœæ©Ÿå™¨äººï¼Œéš¨æ™‚ç‚ºæ‚¨æœå‹™ã€‚",
}

embedding = HuggingFaceEmbeddings(
    model_name="sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2"
)

# âœ… FAISS æ›¿ä»£ Chroma
persist_path = "faiss_index"
if os.path.exists(persist_path):
    vectordb = FAISS.load_local(persist_path, embedding, allow_dangerous_deserialization=True)
else:
    texts = [
        "å…¨è¯æ¯é€±ä¸‰æœƒå“¡æ—¥æœ‰æŒ‡å®šå•†å“æŠ˜æ‰£ã€‚",
        "åŠ å…¥ PX Pay å¯äº«æ›´å¤šå…¨è¯é»æ•¸å›é¥‹ã€‚",
        "ä¸­å…ƒç¯€æœ‰ç”Ÿé®®ç‰¹è³£æ´»å‹•ï¼Œè«‹é—œæ³¨å®˜æ–¹å…¬å‘Šã€‚",
    ]
    vectordb = FAISS.from_texts(texts, embedding)
    vectordb.save_local(persist_path)

def query_with_rag_claude(query: str, api_key: str, model="anthropic/claude-3-haiku") -> str:
    docs = vectordb.similarity_search(query, k=3)
    context = "\n".join([doc.page_content for doc in docs])
    prompt = f"""ä½ æ˜¯ä¸€ä½å…¨è¯çš„å®¢æœäººå“¡ã€‚è«‹æ ¹æ“šä»¥ä¸‹è³‡æ–™å›ç­”é¡§å®¢çš„å•é¡Œï¼š

ã€å…§éƒ¨è³‡æ–™ã€‘
{context}

ã€é¡§å®¢å•é¡Œã€‘
{query}

è«‹ç”¨è¦ªåˆ‡ã€ç°¡æ½”çš„æ–¹å¼å›ç­”ã€‚
"""
    headers = {
        "Authorization": f"Bearer {api_key}",
        "Content-Type": "application/json"
    }
    payload = {
        "model": model,
        "messages": [{"role": "user", "content": prompt}]
    }
    res = requests.post("https://openrouter.ai/api/v1/chat/completions", headers=headers, json=payload)
    if res.status_code == 200:
        return res.json()["choices"][0]["message"]["content"]
    else:
        return "âŒ å›è¦†éŒ¯èª¤ï¼š" + res.text

user_input = st.text_input("è«‹è¼¸å…¥æ‚¨çš„å•é¡Œï¼š", key="user_input")

if user_input:
    if user_input in faq_responses:
        st.success(f"ğŸ¤–ï¼š{faq_responses[user_input]}")
    else:
        with st.spinner("ğŸ¤” æ­£åœ¨æŸ¥æ‰¾è³‡æ–™èˆ‡æ’°å¯«å›è¦†ä¸­..."):
            reply = query_with_rag_claude(user_input, OPENROUTER_API_KEY)
            st.success(f"ğŸ¤–ï¼š{reply}")
