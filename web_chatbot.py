#fg
import os
import streamlit as st
import requests

# âœ… å¼·åˆ¶ Streamlit watcher é—œé–‰ï¼ˆé¿å… torch crashï¼‰
os.environ["STREAMLIT_WATCHER_TYPE"] = "none"

# âœ… é é¢è¨­å®š
st.set_page_config(page_title="å®¢æœtest", page_icon="ğŸ’¬")
st.markdown("<h1 style='font-size:30px; color:#F63366;'>å®¢æœtest ğŸ’¬</h1>", unsafe_allow_html=True)
st.markdown("æ‚¨å¥½ï¼Œæœ‰ä»»ä½•å•é¡Œéƒ½å¯ä»¥å•æˆ‘å–”ï¼")

# âœ… API Key è¨­å®š
OPENROUTER_API_KEY = st.secrets.get("OPENROUTER_API_KEY") or os.getenv("OPENROUTER_API_KEY")
if not OPENROUTER_API_KEY:
    st.error("âŒ è«‹å…ˆè¨­å®šä½ çš„ OpenRouter API Keyï¼ˆç’°å¢ƒè®Šæ•¸æˆ– secretsï¼‰")
    st.stop()

# âœ… FAQ å¿«å–è³‡æ–™
faq_responses = {
    "å¦‚ä½•è¯çµ¡å®¢æœ": "æ‚¨å¯ä»¥é€é support@example.com è¯çµ¡æˆ‘å€‘çš„å®¢æœåœ˜éšŠã€‚",
    "ç‡Ÿæ¥­æ™‚é–“": "æˆ‘å€‘çš„å®¢æœç‡Ÿæ¥­æ™‚é–“ç‚ºé€±ä¸€è‡³é€±äº” 09:00 è‡³ 18:00ã€‚",
    "ä½ æ˜¯èª°": "æˆ‘æ˜¯å…¨è¯ç·šä¸Šæ–‡å­—å®¢æœï¼Œéš¨æ™‚ç‚ºæ‚¨æœå‹™ã€‚",
}

# âœ… è¼‰å…¥ FAISS èˆ‡ Embedding æ¨¡å‹
try:
    from langchain_community.vectorstores import FAISS
    from langchain_huggingface import HuggingFaceEmbeddings
except ImportError as e:
    st.error(f"âŒ æ¨¡çµ„è¼‰å…¥å¤±æ•—ï¼š{e}")
    st.stop()

try:
    embedding = HuggingFaceEmbeddings(
        model_name="sentence-transformers/all-MiniLM-L6-v2",
        model_kwargs={"device": "cpu"}
    )
except Exception as e:
    st.error(f"âŒ æ¨¡å‹è¼‰å…¥å¤±æ•—ï¼š{e}")
    st.stop()

# å‘é‡è³‡æ–™åº«åˆå§‹åŒ–ï¼ˆåƒ…è®€å–æ—¢æœ‰çš„ faiss_indexï¼‰
persist_path = "faiss_index"
if os.path.exists(persist_path):
    try:
        vectordb = FAISS.load_local(persist_path, embedding, allow_dangerous_deserialization=True)
        print("âœ… å‘é‡åº«è¼‰å…¥æˆåŠŸï¼Œè³‡æ–™ç­†æ•¸ï¼š", vectordb.index.ntotal)
    except Exception as e:
        st.error(f"âŒ è¼‰å…¥å‘é‡åº«å¤±æ•—ï¼š{e}")
        st.stop()
else:
    st.error("âŒ æœªæ‰¾åˆ°å‘é‡è³‡æ–™åº«ï¼Œè«‹å…ˆåŸ·è¡Œçˆ¬èŸ²ä¸¦å»ºç«‹ faiss_index/")
    st.stop()

# âœ… Claude å›ç­”å‡½å¼ï¼ˆRAGï¼‰
def query_with_rag_claude(query: str, api_key: str, model="anthropic/claude-3-haiku") -> str:
    #docs = vectordb.similarity_search(query, k=5)
    #context = "\n".join([doc.page_content for doc in docs])
    docs = vectordb.similarity_search(query, k=5)
    st.write("ğŸ” ç³»çµ±æŸ¥å¾—ç›¸è¿‘è³‡æ–™ï¼š")
    for doc in docs:
    	st.markdown(f"- `{doc.page_content}`")
context = "\n".join([doc.page_content for doc in docs])

    prompt = f"""ä½ æ˜¯ä¸€ä½å…¨è¯çš„å®¢æœäººå“¡ã€‚è«‹æ ¹æ“šä»¥ä¸‹è³‡æ–™å›ç­”é¡§å®¢çš„å•é¡Œï¼š

ã€å…§éƒ¨è³‡æ–™ã€‘
{context}

ã€é¡§å®¢å•é¡Œã€‘
{query}

è«‹ç”¨è¦ªåˆ‡çš„æ–¹å¼å›ç­”ã€‚
"""

    headers = {
        "Authorization": f"Bearer {api_key}",
        "Content-Type": "application/json"
    }

    payload = {
        "model": model,
        "messages": [{"role": "user", "content": prompt}]
    }

    res = requests.post("https://openrouter.ai/api/v1/chat/completions", headers=headers, json=payload)
    if res.status_code == 200:
        return res.json()["choices"][0]["message"]["content"]
    else:
        return "âŒ éŒ¯èª¤ï¼š" + res.text

# âœ… å¤šè¼ªå°è©±åˆå§‹åŒ–
if "chat_history" not in st.session_state:
    st.session_state.chat_history = []

# âœ… ä½¿ç”¨è€…è¼¸å…¥
user_input = st.chat_input("è«‹è¼¸å…¥æ‚¨çš„å•é¡Œï¼š")

if user_input:
    st.session_state.chat_history.append({"role": "user", "content": user_input})

    # å›å‚³ FAQ æˆ– Claude å›è¦†
    if user_input in faq_responses:
        reply = faq_responses[user_input]
    else:
        with st.spinner("ğŸ§  æ­£åœ¨æŸ¥æ‰¾è³‡æ–™èˆ‡æ’°å¯«å›è¦†ä¸­..."):
            reply = query_with_rag_claude(user_input, OPENROUTER_API_KEY)

    st.session_state.chat_history.append({"role": "assistant", "content": reply})

# âœ… é¡¯ç¤ºå°è©±æ­·å²
for msg in st.session_state.chat_history:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])

